[{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"recent developments methods applied empirical micro, can difficult keep everything organized. try synthetic control? instrument, tests run? sensitive IV results outliers weak instruments? name RD test , people bin outcome first?put diagrams links together help keep straight. aren’t comprehensive, think serve decent reference key things keep mind, standard tests consider, alternative estimators (relevant). ’m updating things constantly find new information correct misunderstanding. see something awry, please let know!Now, goal teach statistics given estimator research design.goal navigate stuff can even rely results estimation. Estimating something RD, DD, IV one thing, providing convincing evidence causal effect much bigger question (, argue, implicit goal anyone using methods anyway).","code":""},{"path":"endogeneity.html","id":"endogeneity","chapter":"2 Endogeneity","heading":"2 Endogeneity","text":"great test whether really endogeneity problem . alas, ’s just cards. Instead, good starting point see “much” endogeneity problem ’d overturn current results. several papers area. , ’ll mention just two also supporting Stata R code. papers Oster 2019 Cinelli Hazlett 2020.cases, idea follows… Lots applied researchers assess “coefficient stability” including different sets control variables intended proxy potentially important unobserved factor. informative omitted variables bias existing controls already poor job explaining outcome. Prof. Oster notes, “Omitted variable bias proportional coefficient movements, movements scaled change R-squared controls included.”","code":""},{"path":"endogeneity.html","id":"oster","chapter":"2 Endogeneity","heading":"2.1 Oster 2019","text":"Extending work Altonji, Elder, Taber (2005), Oster (2019) lays scenario can fully decompose outcome interest treatment effect (denoted \\(\\beta\\)), observed controls (denoted \\(W_{1}\\)), unobserved controls (denoted \\(W_{2}\\)), iid error term. Denote \\(X\\) treatment variable, \\[\nY = \\beta X + W_{1} + W_{2} + \\epsilon.\n\\]need consider values (range values) two key objects.maximum \\(R^2\\) value obtain observed \\(W_{2}\\)? Let’s call \\(R_{\\text{max}}^{2}\\). think outcome fully deterministic observe relevant variables, \\(R_{\\text{max}}^{2}=1\\), consider smaller values well.maximum \\(R^2\\) value obtain observed \\(W_{2}\\)? Let’s call \\(R_{\\text{max}}^{2}\\). think outcome fully deterministic observe relevant variables, \\(R_{\\text{max}}^{2}=1\\), consider smaller values well.degree selection observed variables relative unobserved variables? can denote value \\(\\delta\\), define \\(\\delta\\) value : \\[\\delta \\times \\frac{Cov(W_{1},X)}{Var(W_{1})} = \\frac{Cov(W_{2},X)}{Var(W_{2})}.\\]degree selection observed variables relative unobserved variables? can denote value \\(\\delta\\), define \\(\\delta\\) value : \\[\\delta \\times \\frac{Cov(W_{1},X)}{Var(W_{1})} = \\frac{Cov(W_{2},X)}{Var(W_{2})}.\\]need define objects can directly estimate data:Denote \\(R^{2}_{X}\\) \\(R^{2}\\) regression \\(Y\\) treatment (treatment, covariates). Similarly denote \\(\\hat{\\beta}_{X}\\) value \\(\\beta\\) estimated regression.Denote \\(R^{2}_{X}\\) \\(R^{2}\\) regression \\(Y\\) treatment (treatment, covariates). Similarly denote \\(\\hat{\\beta}_{X}\\) value \\(\\beta\\) estimated regression.Denote \\(R^{2}_{X,W_{1}}\\) \\(R^{2}\\) regression \\(Y\\) treatment observed controls. , denote estimated value \\(\\beta\\) regression \\(\\hat{\\beta}_{X, W_{1}}\\).Denote \\(R^{2}_{X,W_{1}}\\) \\(R^{2}\\) regression \\(Y\\) treatment observed controls. , denote estimated value \\(\\beta\\) regression \\(\\hat{\\beta}_{X, W_{1}}\\).assumption relative size coefficients regression \\(Y\\) \\(X\\) observed variables equal regression \\(X\\) observed variables, Oster (2019) shows true coefficient interest (\\(\\beta\\) full regression) converges following:\\[\\beta^{*} \\approx \\hat{\\beta}_{X,W_{1}} - \\delta \\times \\left[\\hat{\\beta}_{X} - \\hat{\\beta}_{X,W_{1}}\\right] \\times \\frac{R_{max}^{2} - R_{X,W_{1}}^{2}}{R_{X,W_{1}}^{2} - R_{X}^{2}} \\xrightarrow{p} \\beta.\\]relax assumption equal “relative contributions” observed covariates \\(Y\\) versus observed covariates \\(X\\), results little complicated. case, Oster (2019) shows \\[\\beta^{*} = \\hat{\\beta}_{X,W_{1}} - \\nu_{1} \\xrightarrow{p} \\beta,\\] \\[\\beta^{*} \\\\left\\{ \\hat{\\beta}_{X,W_{1}} - \\nu_{1}, \\hat{\\beta}_{X,W_{1}} - \\nu_{2}, \\hat{\\beta}_{X,W_{1}} - \\nu_{3} \\right\\},\\]\n\\(\\nu_{1}\\), \\(\\nu_{2}\\), \\(\\nu_{3}\\) roots cubic function, \\(f(\\nu)\\), derived paper. case one root, one element \\(\\beta^{*}\\) converges probability \\(\\beta\\). \\(\\delta=1\\), additional simplifications can made, point now expression bias function \\(\\delta\\) \\(R^{2}_{max}\\).gain ? Well, Oster (2019) shows can also work backwards find value \\(\\delta\\) \\(\\beta=0\\). words, say estimate using OLS effect, \\(\\hat{\\beta}_{X, W_{1}}\\). big must role selection unobservables order completely overpower estimate true effect actually 0?Another approach consider range \\(R^{2}_{max}\\) \\(\\delta\\) bound estimated treatment effect. Using \\(\\delta=1\\) upper bound \\(\\delta\\) (.e., observables least important unobservables), \\(\\bar{R}^{2}_{max}\\) upper bound \\(R^{2}_{max}\\), bounds \\(\\beta^{*}\\) \\(\\left[ \\hat{\\beta}_{X,W_{1}}, \\beta^{*}(\\bar{R}^{2}_{max}, 1) \\right]\\).Finally, Oster (2019) suggests setting \\(\\delta=1\\) identifying value \\(R^{2}_{max}\\) \\(\\beta=0\\). tell us much variation \\(Y\\) need explained unobservables order true effect null (given estimate, \\(\\hat{\\beta}_{X,W_{1}}\\).also Stata command, psacalc, calculations us (’re Stata user).","code":""},{"path":"endogeneity.html","id":"cinelli","chapter":"2 Endogeneity","heading":"2.2 Cinelli and Hazlett 2020","text":"Cinelli Hazlett (2020) offers general approach require functional form assumptions treatment assignment distribution unobserved confounders. intuition approach similar, see general Oster (2019) others. said, one sensitivity measure proposed Cinelli Hazlett (2020) requires users impose form “baseline” covariate order gauge relative strength omitted variables. variable specified, can consider big confounding must relative relationship estimated data. say “relationship” . ’m entirely clearly measure works estimated relationship subject endogeneity concerns.Nonetheless, also program implement analysis Stata R, sensemakr.","code":""},{"path":"endogeneity.html","id":"references","chapter":"2 Endogeneity","heading":"2.3 References","text":"","code":""},{"path":"instrumental-variables.html","id":"instrumental-variables","chapter":"3 Instrumental Variables","heading":"3 Instrumental Variables","text":"","code":""},{"path":"instrumental-variables.html","id":"does-iv-do-anything","chapter":"3 Instrumental Variables","heading":"3.1 Does IV do anything?","text":"great test whether need IV . can’t really , can least see different IV results might relative OLS (assuming decent instruments already).easy way assess need IV simply test whether IV results sufficiently different OLS. ’s spirit Hausman test. original test introduced Hausman (1978) specific endogeneity…’s general misspecification test, comparing estimates one estimator (efficient null) another estimator consistent inefficient null. test context IV also referred Durbin-Wu-Hausman test, due series papers pre-dating Hausman (1978), including Durbin (1954), Wu (1973), Wu (1974).test easily implemented “artificial” “augmented” regression. Denoting outcome \\(y\\), instruments \\(z\\), endogeous variables \\(x_{1}\\), exogenous variables \\(x_{2}\\), first regress variables \\(x_{1}\\) \\(x_{2}\\) \\(z\\). take residuals regressions, denoted \\(\\hat{v}\\), include standard OLS regression \\(y\\) \\(x_{1}\\), \\(x_{2}\\), \\(\\hat{v}\\).biggest barrier test practice assumes valid strong set instruments, \\(z\\). Since ’s usually biggest barrier causal inference IV, becomes major practical problem. example, reject null conclude estimates OLS IV statistically different, can sure difference “real” statistical artifact weak invalid instruments? whole process becomes pretty circular.\n","code":""},{"path":"instrumental-variables.html","id":"references-1","chapter":"3 Instrumental Variables","heading":"3.2 References","text":"","code":""},{"path":"difference-in-differences.html","id":"difference-in-differences","chapter":"4 Difference-in-Differences","heading":"4 Difference-in-Differences","text":"","code":""},{"path":"difference-in-differences.html","id":"what-is-panel-data","chapter":"4 Difference-in-Differences","heading":"4.1 What is Panel Data?","text":"Panel data describes setting repeated observations time units (e.g., people, firms, counties, etc.). data often present opportunity estimate causal effects convincingly purely cross-sectional setting, although ’s certainly always case. ’d much rather read strong analysis “lesser” data poor analysis “better” data. else equal, panel data tend contain information dimensions variation see cross-sectional data, thus opportunities causal inference.Slightly formally, observe outcome \\(y\\) units \\(=1,...,N\\) time periods \\(t=1,...,T\\). denote outcome given unit time \\(y_{}\\). Keeping potential outcomes framework notation, let’s assume units receive treatment time \\(t\\), denote indicator \\(1(D_{}=1)\\). also observe time-varying characteristics unit, denoted \\(W_{}\\).","code":""},{"path":"difference-in-differences.html","id":"what-is-difference-in-differences","chapter":"4 Difference-in-Differences","heading":"4.2 What is Difference-in-Differences?","text":"Difference--differences (DD) identification strategy essentially attempts predict counterfactual treated group using change outcomes among control group. Intuitively, assume outcomes ultimately received treatment evolved just outcomes receive treatment (average).","code":""},{"path":"difference-in-differences.html","id":"twfe-and-event-studies","chapter":"4 Difference-in-Differences","heading":"4.3 TWFE and Event Studies","text":"Two-way fixed effects (TWFE) essentially just shorthand specific common regression specification includes fixed effects units \\(=1,...,N\\) time \\(t=1,...,T\\). ’ll denote \\(\\gamma_{}\\) \\(\\gamma_{t}\\), respectively. TWFE general 2x2 DD specification allows intercept shifts units time period, opposed shifts among treated/control group treated/control period. However, extra generality doesn’t really much case single treated group single treatment time, since overall group overall treatment period dummies 2x2 case effectively average individual unit individual time period fixed effects, respectively.formally, recall original DD regression specification,\\(y_{} = \\alpha + \\beta \\times 1(Post) + \\lambda \\times 1(Treat) + \\delta \\times 1(Post) \\times 1(Treat) + \\varepsilon\\). , single treated group single treatment time, capture treatment time post-period indicator, treated group treatment indicator, interaction two variables treatment effect interest. can generalize allow dummies unit (rather treated/control group) similarly time period (rather pre/post groups). doesn’t change treatment effect estimates, “efficient” (standard errors going smaller). yields following regression specification: \\[y_{} = \\alpha + \\delta D_{} + \\gamma_{} + \\gamma_{t} + \\varepsilon,\\]\n\\(\\gamma_{}\\) \\(\\gamma_{t}\\) denote set unit \\(\\) time period \\(t\\) dummy variables (fixed effects), \\(\\delta\\) captures treatment effect interest just .","code":""},{"path":"difference-in-differences.html","id":"presentations","chapter":"4 Difference-in-Differences","heading":"4.4 Presentations","text":"presentations ’ve made different settings. less repeat information presentation format (figures, fewer words).Intro Panel Data, CDC Workshop, August 2021Basics DD, CDC Workshop, August 2021TWFE Event Studies, CDC Workshop, August 2021Recent DD Advancements, CDC Workshop, August 2021Recent Panel Advancements, CDC Workshop, August 2021","code":""},{"path":"difference-in-differences.html","id":"code-files","chapter":"4 Difference-in-Differences","heading":"4.5 Code Files","text":"good discussion data econometrics without practice?! basic code files implement estimators described .","code":""},{"path":"difference-in-differences.html","id":"intro-to-panel-data","chapter":"4 Difference-in-Differences","heading":"4.5.1 Intro to Panel Data","text":"","code":"****************************************\n** Panel data estimates in Stata\n****************************************\n\n** FE (within) estimator\nssc install bcuse\nbcuse wagepan\nxtset nr year\nxtreg lwage exper expersq, fe\n\n\n** Manually demeaning the data\nforeach x of varlist lwage exper expersq {\n  egen mean_`x'=mean(`x')\n  egen demean_`x'=`x'-mean_`x'\n}\nreg demean_lwage demean_exper demean_expersq\n\n\n** First differencing\n** note: the \"d.\" operator only works with identical time gaps (1 in this case)\nreg d.lwage d.exper d.expersq, noconstant\n########################################\n## Panel data estimates in R\n########################################\n  \n## FE (within) estimator\nlibrary(readstata13)\nlibrary(fixest)\nwagepan <- read.dta13(\"http://fmwww.bc.edu/ec-p/data/wooldridge/wagepan.dta\")\nfeols(lwage~exper + expersq | nr, data=wagepan)\n\n\n## Manually demeaning the data\nwagepan <- wagepan %>%\n  group_by(nr) %>%\n  mutate(demean_lwage=lwage - mean(lwage),\n         demean_exper=exper - mean(exper),\n         demean_expersq=expersq - mean(expersq))\nsummary(lm(demean_lwage~demean_exper + demean_expersq, data=wagepan))\n\n\n## First differencing\nwagepan <- wagepan %>%\n  group_by(nr) %>%\n  arrange(year) %>%\n  mutate(fd_lwage=lwage - lag(lwage),\n         fd_exper=exper - lag(exper),\n         fd_expersq=expersq - lag(expersq)) %>%\n  na.omit()\nsummary(lm(fd_lwage~0 + fd_exper + fd_expersq, data=wagepan))"},{"path":"difference-in-differences.html","id":"basics-of-dd","chapter":"4 Difference-in-Differences","heading":"4.5.2 Basics of DD","text":"","code":"****************************************\n** Differences-in-Differences in Stata\n****************************************\ninsheet using \"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\", clear\n\n\n** Looking at the data\ngen perc_unins=uninsured/adult_pop\nkeep if expand_year==\"2014\" | expand_year==\"NA\"\ndrop if expand_ever==\"NA\"\ncollapse (mean) perc_unins, by(year expand_ever)\ngraph twoway (connected perc_unins year if expand_ever==\"FALSE\", color(black) lpattern(solid)) ///\n  (connected perc_unins year if expand_ever==\"TRUE\", color(black) lpattern(dash)), ///\n  xline(2013.5) ///\n    ytitle(\"Fraction Uninsured\") xtitle(\"Year\") legend(off) text(0.15 2017 \"Non-expansion\", place(e)) text(0.08 2017 \"Expansion\", place(e))\n\n\n** Simple 2x2 DD\ngen post=(year>=2014)\ngen treat=(expand_ever==\"TRUE\")\ngen treat_post=(expand==\"TRUE\")\n\nreg perc_unins treat post treat_post\n\n** note - Stata 17 has didregress that will do a lot of this automatically\n########################################\n## Difference-in-Differences in R\n########################################\nlibrary(tidyverse)  \nmcaid.data <- read_tsv(\"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\")\n\n## Looking at the data\nins.plot.dat <- mcaid.data %>% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop) %>%\n  group_by(expand_ever, year) %>% summarize(mean=mean(perc_unins))\n\nins.plot <- ggplot(data=ins.plot.dat, aes(x=year,y=mean,group=expand_ever,linetype=expand_ever)) + \n  geom_line() + geom_point() + theme_bw() +\n  geom_vline(xintercept=2013.5, color=\"red\") +\n  geom_text(data = ins.plot.dat %>% filter(year == 2016), \n            aes(label = c(\"Non-expansion\",\"Expansion\"),\n                x = year + 1,\n                y = mean)) +\n  guides(linetype=FALSE) +\n  labs(\n    x=\"Year\",\n    y=\"Fraction Uninsured\",\n    title=\"Share of Uninsured over Time\"\n  )\n\n\n## Simple 2x2 DD\nreg.dat <- mcaid.data %>% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever)\n\ndd.ins.reg <- lm(perc_unins ~ post + expand_ever + post*expand_ever, data=reg.dat)\nmsummary(dd.ins.reg)"},{"path":"difference-in-differences.html","id":"twfe-and-event-studies-1","chapter":"4 Difference-in-Differences","heading":"4.5.3 TWFE and Event Studies","text":"","code":"****************************************\n** Event Studies in Stata\n****************************************\nssc install reghdfe\n\n** Common treatment timing\ninsheet using \"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\", clear\ngen perc_unins=uninsured/adult_pop\nkeep if expand_year==\"2014\" | expand_year==\"NA\"\ndrop if expand_ever==\"NA\"\ngen post=(year>=2014)\ngen treat=(expand_ever==\"TRUE\")\ngen treat_post=(expand==\"TRUE\")\n\nreghdfe perc_unins treat##ib2013.year, absorb(state)\ngen coef = .\ngen se = .\nforvalues i = 2012(1)2018 {\n    replace coef = _b[1.treat#`i'.year] if year == `i'\n    replace se = _se[1.treat#`i'.year] if year == `i'\n}\n\n* Make confidence intervals\ngen ci_top = coef+1.96*se\ngen ci_bottom = coef - 1.96*se\n\n* Limit ourselves to one observation per year\nkeep year coef se ci_*\nduplicates drop\n\n* Create connected scatterplot of coefficients\n* with CIs included with rcap \n* and a line at 0 from function\ntwoway (sc coef year, connect(line)) (rcap ci_top ci_bottom year) ///\n    (function y = 0, range(2012 2018)), xtitle(\"Year\") ///\n    caption(\"Estimates and 95% CI from Event Study\")\n\n\n\n** Differential treatment timing\ninsheet using \"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\", clear\ngen perc_unins=uninsured/adult_pop\ndrop if expand_ever==\"NA\"\nreplace expand_year=\".\" if expand_year==\"NA\"\ndestring expand_year, replace\ngen event_time=year-expand_year\nreplace event_time=-1 if event_time==.\n\nforvalues l = 0/4 {\n    gen L`l'event = (event_time==`l')\n}\nforvalues l = 1/2 {\n    gen F`l'event = (event_time==-`l')\n}\ngen F3event=(event_time<=-3)\n\nreghdfe perc_unins F3event F2event L0event L1event L2event L3event L4event, absorb(state year) cluster(state)\ngen coef = .\ngen se = .\nforvalues i = 2(1)3 {\n    replace coef = _b[F`i'event] if F`i'event==1\n    replace se = _se[F`i'event] if F`i'event==1\n}\nforvalues i = 0(1)4 {\n    replace coef = _b[L`i'event] if L`i'event==1\n    replace se = _se[L`i'event] if L`i'event==1\n}\nreplace coef = 0 if F1event==1\nreplace se=0 if F1event==1\n\n* Make confidence intervals\ngen ci_top = coef+1.96*se\ngen ci_bottom = coef - 1.96*se\n\n* Limit ourselves to one observation per year\nkeep if event_time>=-3 & event_time<=4\nkeep event_time coef se ci_*\nduplicates drop\n\n* Create connected scatterplot of coefficients\n* with CIs included with rcap \n* and a line at 0 from function\nsort event_time\ntwoway (sc coef event_time, connect(line)) (rcap ci_top ci_bottom event_time) ///\n    (function y = 0, range(-3 4)), xtitle(\"Time\") ///\n    caption(\"Estimates and 95% CI from Event Study\") xlabel(-3(1)4)\n########################################\n## Event Studies in R\n########################################\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(data.table)\nlibrary(fixest)\nmcaid.data <- read_tsv(\"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\")\n\n## Common treatment timing\nreg.dat <- as.data.table(mcaid.data) %>% \n  filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever)\n\nmod.twfe <- feols(perc_unins~i(year, expand_ever, ref=2013) | State + year,\n                  cluster=~State,\n                  data=reg.dat)\niplot(mod.twfe, \n      xlab = 'Time to treatment',\n      main = 'Event study')\n\n\n## Differential treatment timing\nreg.dat <- as.data.table(mcaid.data) %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop)\nreg.dat[, time_to_treat := ifelse(expand_ever==TRUE, year-expand_year, 0)]\n\nreg.dat <- reg.dat %>%\n  mutate(time_to_treat=ifelse(time_to_treat<=-3,-3,time_to_treat))\n\nmod.twfe <- feols(perc_unins~i(time_to_treat, expand_ever, ref=-1) | State + year,\n                  cluster=~State,\n                  data=reg.dat)\niplot(mod.twfe, \n      xlab = 'Time to treatment',\n      main = 'Event study')"},{"path":"difference-in-differences.html","id":"recent-dd-advancements","chapter":"4 Difference-in-Differences","heading":"4.5.4 Recent DD Advancements","text":"","code":"****************************************\n** Recent DD Estimators in Stata\n****************************************\nssc install event_plot\n\n\n** Callaway and Sant'Anna\nssc install csdid\nssc install drdid\n\ninsheet using \"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\", clear\ngen perc_unins=uninsured/adult_pop\negen stategroup=group(state)\ndrop if expand_ever==\"NA\"\nreplace expand_year=\"0\" if expand_year==\"NA\"\ndestring expand_year, replace\n\ncsdid perc_unins, ivar(stategroup) time(year) gvar(expand_year) notyet\nestat event, estore(cs)\nevent_plot cs, default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") xlabel(-6(1)4) title(\"Callaway and Sant'Anna (2020)\")) stub_lag(T+#) stub_lead(T-#) together\n\n\n\n** Callaway and Sant'Anna\nssc install csdid\nssc install drdid\n\ninsheet using \"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\", clear\ngen perc_unins=uninsured/adult_pop\negen stategroup=group(state)\ndrop if expand_ever==\"NA\"\nreplace expand_year=\"0\" if expand_year==\"NA\"\ndestring expand_year, replace\n\ncsdid perc_unins, ivar(stategroup) time(year) gvar(expand_year) notyet\nestat event, estore(cs)\nevent_plot cs, default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") xlabel(-6(1)4) title(\"Callaway and Sant'Anna (2020)\")) stub_lag(T+#) stub_lead(T-#) together\n\n\n\n** Sun and Abraham\nssc install eventstudyinteract\nssc install avar\n\ninsheet using \"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\", clear\ngen perc_unins=uninsured/adult_pop\ndrop if expand_ever==\"NA\"\negen stategroup=group(state)\nreplace expand_year=\".\" if expand_year==\"NA\"\ndestring expand_year, replace\ngen event_time=year-expand_year\ngen nevertreated=(event_time==.)\n\nforvalues l = 0/4 {\n    gen L`l'event = (event_time==`l')\n}\nforvalues l = 1/2 {\n    gen F`l'event = (event_time==-`l')\n}\ngen F3event=(event_time<=-3)\neventstudyinteract perc_unins F3event F2event L0event L1event L2event L3event L4event, vce(cluster stategroup) absorb(stategroup year) cohort(expand_year) control_cohort(nevertreated)\n\nevent_plot e(b_iw)#e(V_iw), default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") xlabel(-3(1)4) title(\"Sun and Abraham (2020)\")) stub_lag(L#event) stub_lead(F#event) plottype(scatter) ciplottype(rcap) together\n\n\n\n** de Chaisemartin and D'Haultfoeuille\nssc install did_multiplegt\n\ninsheet using \"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\", clear\ngen perc_unins=uninsured/adult_pop\ndrop if expand_ever==\"NA\"\negen stategroup=group(state)\nreplace expand_year=\".\" if expand_year==\"NA\"\ndestring expand_year, replace\ngen event_time=year-expand_year\ngen nevertreated=(event_time==.)\ngen treat=(event_time>=0 & event_time!=.)\n\ndid_multiplegt perc_unins stategroup year treat, robust_dynamic dynamic(4) placebo(3) breps(100) cluster(stategroup) \nevent_plot e(estimates)#e(variances), default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") ///\ntitle(\"de Chaisemartin and D'Haultfoeuille (2020)\") xlabel(-3(1)4)) stub_lag(Effect_#) stub_lead(Placebo_#) together\n########################################\n## Recent DD Estimators in R\n########################################\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(data.table)\nlibrary(fixest)\nmcaid.data <- read_tsv(\"https://raw.githubusercontent.com/imccart/empirical-methods/main/data/medicaid-expansion/mcaid-expand-data.txt\")\n\n\n## Callaway and Sant'Anna\nlibrary(did)\nlibrary(DRDID)\n\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever,\n         expand_year=ifelse(is.na(expand_year),0,expand_year)) %>%\n  filter(!is.na(perc_unins)) %>%\n  group_by(State) %>%\n  mutate(stategroup=cur_group_id()) %>% ungroup()\n\nmod.cs <- att_gt(yname=\"perc_unins\", tname=\"year\", idname=\"stategroup\",\n                 gname=\"expand_year\",\n                 data=reg.dat, panel=TRUE, est_method=\"dr\",\n                 allow_unbalanced_panel=TRUE)\nmod.cs.event <- aggte(mod.cs, type=\"dynamic\")\nggdid(mod.cs.event)\n\n\n## Sun and Abraham\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year>=2014), \n         treat=post*expand_ever,\n         expand_year = ifelse(expand_ever==FALSE, 10000, expand_year),\n         time_to_treat = ifelse(expand_ever==FALSE, -1, year-expand_year),\n         time_to_treat = ifelse(time_to_treat < -3, -3, time_to_treat))\n\nmod.sa <- feols(perc_unins~sunab(expand_year, time_to_treat) | State + year,\n                cluster=~State,\n                data=reg.dat)\niplot(mod.sa,\n      xlab = 'Time to treatment',\n      main = 'Event study')\n\n\n## de Chaisemartin and D'Haultfoeuille\nlibrary(DIDmultiplegt)\nreg.dat <- mcaid.data %>% \n  filter(!is.na(expand_ever)) %>%\n  mutate(perc_unins=uninsured/adult_pop,\n         treat=case_when(\n           expand_ever==FALSE ~ 0,\n           expand_ever==TRUE & expand_year<year ~ 0,\n           expand_ever==TRUE & expand_year>=year ~ 1))\n\nmod.ch <- did_multiplegt(df=reg.dat, Y=\"perc_unins\", G=\"State\", T=\"year\", D=\"treat\",\n                         placebo=3, dynamic=4, brep=50, cluster=\"State\")\nmod.ch"}]
