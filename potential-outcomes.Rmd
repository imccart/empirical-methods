---
title: "Section 3: Hospital Pricing and Selection on Observables"
subtitle: "<html><div style='float:left'></div><hr color='#EB811B' size=1px width=0px></html>"
author: Ian McCarthy | Emory University
date: Econ 470 & HLTH 470 #"`r format(Sys.time(), '%d %B %Y')`"
header-includes: 
  - \usepackage{graphicx}
  - \usepackage{amsmath}
output:
  html_document: default
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts, custom.css] 
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "macros.js"
      navigation:
          touch: false
---

<!-- Adjust some CSS code for font size and maintain R code font size -->
<style type="text/css">
.remark-slide-content {
    font-size: 30px;
    padding: 1em 2em 1em 2em;    
}
.remark-code {
  font-size: 15px;
}
.remark-inline-code { 
    font-size: 20px;
}
</style>


<!-- Set R options for how code chunks are displayed and load packages -->
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
knitr::opts_chunk$set(
  fig.align="center",  
  fig.height=3, #fig.width=6,
  # out.width="748px", #out.length="520.75px",
  dpi=300, #fig.path='Figs/',
  cache=T,# echo=F, warning=F, message=F
  warning = FALSE, 
  message = FALSE, 
  cache.lazy = FALSE,
  error=TRUE
  )

knitr::opts_hooks$set(fig.callout = function(options) {
  if(options$fig.callout) {
    options$echo = FALSE
  }
  options
})

if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, ggplot2, dplyr, lubridate, readr, readxl, hrbrthemes,
               scales, plotly, gganimate, cobalt, MatchIt, ggthemes)
set.seed(12345)
```

# Table of contents

1. [Hospital Pricing](#hospital_pricing)

2. [Potential Outcomes Framework](#potential_outcomes)

3. [Selection on Observables](#selection_observables)

4. [Methods](#methods)

5. [HCRIS Data](#hcris)

6. [Pricing and Pay for Performance](#price_pfp)

<!-- New Section -->
---
class: inverse, center, middle
name: hospital_pricing

# Background on Hospital Pricing

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>

---
# What is a hospital price?

Defining characteristic of hospital services: *it's complicated!*

--
.center[
  ![:scale 800px](pics/BillExample.jpg)
]

<div class="smalltext">Brill, Steven. 2013. "Bitter Pill: Why Medical Bills are Killing Us." *Time Magazine*.</div>

---
# What is a hospital price?

Lots of different payers paying lots of different prices:
- [Medicare fee-for-service prices](https://www.cms.gov/Outreach-and-Education/Medicare-Learning-Network-MLN/MLNProducts/Downloads/AcutePaymtSysfctsht.pdf)
- [Medicaid payments](https://www.kff.org/report-section/understanding-medicaid-hospital-payments-and-the-impact-of-recent-policy-changes-issue-brief/)
- Private insurance negotiations (including Medicare Advantage)
- But what about the price to patients?

--

.center[
Price $\neq$ charge $\neq$ cost $\neq$ patient out-of-pocket spending
]

---
# What is a hospital price?

.center[
  ![:scale 600px](pics/DifferentPrices.jpg)
]

<div class="smalltext">Source: <a href="https://healthcarepricingproject.org/">Health Care Pricing Project</a></div>


---
# What is a hospital price?
Not clear what exactly is negotiated...

--
.pull-left[
### Fee-for-service
- price per procedure
- percentage of charges
- markup over Medicare rates
]

--
.pull-right[
### Capitation
- payment per patient
- pay-for-performance
- shared savings
]

---
# Hospital prices in real life
We'll get into the real data in a bit, but for now...a few facts:

1. Hospital services are expensive

2. Prices vary dramatically across different areas

3. Lack of competition is a major reason for high prices

---
# Hospital prices in real life

.pull-left[
  ![:scale 450px](pics/HC_var_withinmkt_hip_ga_atlanta.png)
]

.pull-right[
  ![:scale 450px](pics/HC_var_withinmkt_kmri_ga_atlanta.png)
]

<div class="smalltext">Source: <a href="https://healthcarepricingproject.org/">Health Care Pricing Project</a></div>



<!-- New Section -->
---
class: inverse, center, middle
name: potential_outcomes

# Potential Outcomes Framework

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# What is a "Potential Outcome"
.pull-left[
![:scale 420px](pics/EmoryPicture.jpg)

Y(1)= $75,000

]

.pull-right[
![:scale 370px](pics/UNTPicture.jpg)

Y(0)= $60,000
]

--
<html><div style='float:left'></div><hr color='black' size=1px width=1100px></html>
Treatment effect =Y(1)-Y(0)= $15,000

---
# What is a "Potential Outcome"
.pull-left[
![:scale 420px](pics/EmoryPicture.jpg)

Y(1)= $75,000

]

.pull-right[
![:scale 370px](pics/UNTPicture.jpg)

Y(0)= ?
]

--
<html><div style='float:left'></div><hr color='black' size=1px width=1100px></html>
Treatment effect =Y(1)-Y(0)= ?

---
# Do we ever observe the potential outcomes?
.center[
  ![:scale 700px](https://media.giphy.com/media/zZeCRfPyXi9UI/giphy.gif)
]

--
Without a time machine...hard to get *individual* treatment effects.

---
# *Average* Treatment Effect
```{r ate_data, echo=F, eval=T}
ate.data <- tibble(
  x=rnorm(18,5,1),
  z=c(rep("blue",3),rep("red",3),rep("yellow",3),rep("blue",3),rep("red",3),rep("yellow",3)),
  z_lab=c(" "," ","#","#"," "," "," "," "," "," "," "," "," "," "," "," ","#","#"),
  z_alt=c(rep("blue",4),rep("red",3),rep("yellow",2),rep("blue",2),rep("red",3),rep("yellow",4)),  
  t=c(-1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,1,1,1,1,1,1,1),
  e=rnorm(18,0,.1),
  x_disp=rnorm(18,0,0.1)
)
ate.data <- ate.data %>%
  mutate(y=1.5*x + .75*t + e,
         xplust=x_disp+.3*t,
         yplusz=y+ (-10)*(z=="blue") + 10*(z=="yellow"),
         yplusz_alt=y+(-10)*(z_alt=="blue") + 10*(z_alt=="yellow"))
```

```{r ate-plot1, echo=F, include=F}
ggplot(ate.data, aes(x_disp,y)) + 
  geom_point(aes(shape=z, size=5), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15))
```

```{r ate-plot1-output, ref.label="ate-plot1", fig.callout=TRUE, warning=FALSE}
```


---
# *Average* Treatment Effect
```{r ate-plot2, echo=F, include=F}
ggplot(ate.data, aes(x_disp,y)) + 
  geom_point(aes(shape=z, size=5, color=t), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15))
```

```{r ate-plot2-output, ref.label="ate-plot2", fig.callout=TRUE, warning=FALSE}
```


---
# *Average* Treatment Effect
```{r ate-plot3, echo=F, include=F}
plot3 <- ggplot(ate.data, aes(xplust,y)) + 
  geom_point(aes(shape=z, size=5, color=t), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15))
plot3
```
```{r ate-plot3-output, ref.label="ate-plot3", fig.callout=TRUE, warning=FALSE}
```


---
# *Average* Treatment Effect
```{r ate-plot4, echo=F, include=F}
x0 <- ate.data %>% filter(t==-1) %>% select(xplust)
mean.x0 <- mean(x0$xplust)
x1 <- ate.data %>% filter(t==1) %>% select(xplust)
mean.x1 <- mean(x1$xplust)

plot3 + annotate("text",x=mean.x0, y=-2, label="E[Y(1)]", size=5) +
  annotate("text", x=mean.x1, y=-2, label="E[Y(0)]", size=5)
```

```{r ate-plot4-output, ref.label="ate-plot4", fig.callout=TRUE, warning=FALSE}
```

--
$$ATE = E[Y(1)-Y(0)]$$

<!-- New Section -->
---
class: inverse, center, middle
name: selection_observables

# Selection on Observables

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>

---
# Average Treatment Effect
```{r , ref.label="ate-plot2", fig.callout=TRUE, warning=FALSE}
```

---
# ...with Selection
```{r ate-plot-alt, echo=F, include=F}
ggplot(ate.data, aes(x_disp,y)) + 
  geom_point(aes(shape=z_alt, size=5, color=t), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15))
```

```{r , ref.label="ate-plot-alt", fig.callout=TRUE, warning=FALSE}
```

---
# ...with Selection
```{r ate-plot-alt2, echo=F, include=F}
plot.alt <- ggplot(ate.data, aes(xplust,y)) + 
  geom_point(aes(shape=z_alt, size=5, color=t), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15))
plot.alt
```

```{r, ref.label="ate-plot-alt2", fig.callout=TRUE, warning=FALSE}
```


---
# ...with Selection
```{r ate-plot5, echo=F, include=F}
plot5 <- ggplot(ate.data, aes(xplust,yplusz_alt)) + 
  geom_point(aes(shape=z_alt, size=5, color=t), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15))
plot5
```

```{r ate-plot5-output, ref.label="ate-plot5", fig.callout=TRUE, warning=FALSE}
```


---
# ...with Selection
```{r ate-plot6, echo=F, include=F}
x0 <- ate.data %>% filter(t==-1) %>% select(xplust)
mean.x0 <- mean(x0$xplust)
x1 <- ate.data %>% filter(t==1) %>% select(xplust)
mean.x1 <- mean(x1$xplust)

y0.blue <- ate.data %>% filter(t==-1 & z=="blue") %>% select(yplusz_alt)
mean.blue <- mean(y0.blue$yplusz_alt)-.1

y0.yellow <- ate.data %>% filter(t==-1 & z=="yellow") %>% select(yplusz_alt)
mean.yellow <- mean(y0.yellow$yplusz_alt)-.1

y0.red <- ate.data %>% filter(t==-1 & z=="red") %>% select(yplusz_alt)
mean.red <- mean(y0.red$yplusz_alt)-.1


plot5 + annotate("text",x=mean.x0, y=mean.blue, label="E[Y(1)|c]", size=4) +
  annotate("text", x=mean.x1, y=mean.blue, label="E[Y(0)|c]", size=4) +
  annotate("text",x=mean.x0, y=mean.yellow, label="E[Y(1)|s]", size=4) +
  annotate("text",x=mean.x1, y=mean.yellow, label="E[Y(0)|s]", size=4) +
  annotate("text",x=mean.x0, y=mean.red, label="E[Y(1)|t]", size=4) +
  annotate("text",x=mean.x1, y=mean.red, label="E[Y(0)|t]", size=4)
```

```{r ate-plot6-output, ref.label="ate-plot6", fig.callout=TRUE, warning=FALSE}
```

---
# Assumption 1: Selection on Observables
```{r ate-plot7, echo=F, include=F}
plot6 <- ggplot(ate.data, aes(xplust,yplusz_alt)) + 
  geom_point(aes(shape=z_alt, size=5), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15))

diff=(mean.x0+mean.x1)/2
x.end=mean.x1+.3
plot6 + annotate("text",x=mean.x0, y=mean.blue, label="E[Y(1)|c]", size=4) +
  annotate("text", x=mean.x1, y=mean.blue, label="E[Y(0)|c]", size=4) +
  annotate("text",x=mean.x0, y=mean.yellow, label="E[Y(1)|s]", size=4) +
  annotate("text",x=mean.x1, y=mean.yellow, label="E[Y(0)|s]", size=4) +
  annotate("text",x=mean.x0, y=mean.red, label="E[Y(1)|t]", size=4) +
  annotate("text",x=mean.x1, y=mean.red, label="E[Y(0)|t]", size=4) +
  annotate("text",x=diff, y=mean.blue, label="-", size=4) +
  annotate("text",x=diff, y=mean.yellow, label="-", size=4) +
  annotate("text",x=diff, y=mean.red, label="-", size=4) +
  annotate("text",x=x.end, y=mean.blue, label="= E[Y(1)-Y(0)|c]", size=4) +
  annotate("text",x=x.end, y=mean.yellow, label="= E[Y(1)-Y(0)|s]", size=4) +
  annotate("text",x=x.end, y=mean.red, label="= E[Y(1)-Y(0)|t]", size=4)
```

```{r ate-plot7-output, ref.label="ate-plot7", fig.callout=TRUE, warning=FALSE}
```

---
# Assumption 1: Selection on Observables
```{r ate-plot8, echo=F, include=F}
eq.start <- x.end-.1
eq.end <- x.end+.1
eq.y <- mean.blue-1.3
ans.y <- eq.y-1.1
plot6 + annotate("text",x=mean.x0, y=mean.blue, label="E[Y(1)|c]", size=4) +
  annotate("text", x=mean.x1, y=mean.blue, label="E[Y(0)|c]", size=4) +
  annotate("text",x=mean.x0, y=mean.yellow, label="E[Y(1)|s]", size=4) +
  annotate("text",x=mean.x1, y=mean.yellow, label="E[Y(0)|s]", size=4) +
  annotate("text",x=mean.x0, y=mean.red, label="E[Y(1)|t]", size=4) +
  annotate("text",x=mean.x1, y=mean.red, label="E[Y(0)|t]", size=4) +
  annotate("text",x=diff, y=mean.blue, label="-", size=4) +
  annotate("text",x=diff, y=mean.yellow, label="-", size=4) +
  annotate("text",x=diff, y=mean.red, label="-", size=4) +
  annotate("text",x=x.end, y=mean.blue, label="= E[Y(1)-Y(0)|c]", size=4) +
  annotate("text",x=x.end, y=mean.yellow, label="= E[Y(1)-Y(0)|s]", size=4) +
  annotate("text",x=x.end, y=mean.red, label="= E[Y(1)-Y(0)|t]", size=4) +
  annotate("segment", x = eq.start , xend = eq.end, y = eq.y, yend = eq.y, colour = "black") +
  annotate("text",x=x.end, y=ans.y, label="ATE=E[Y(1)-Y(0)]", size=4)
```

```{r ate-plot8-output, ref.label="ate-plot8", fig.callout=TRUE, warning=FALSE}
```

---
# Assumption 1: Selection on Observables

More formally:

--
<br>
<br>
- $E[Y(1)|W,shape]=E[Y(1)|shape]$
- $Y(1),Y(0) \perp\!\!\!\perp W | shape$


--
<br>

In words...nothing unobserved that determines treatment selection and affects your outcome of interest.

---
# Violation of Selection on Observables
```{r ate-select, echo=F, include=F}
plot6 <- ggplot(ate.data, aes(xplust,yplusz_alt)) + 
  geom_point(aes(shape=z_alt, size=5), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15))
plot6
```

```{r ate-select-output, ref.label="ate-select", fig.callout=TRUE, warning=FALSE}
```

---
# Violation of Selection on Observables
```{r ate-plot9, echo=F, include=F}
plot7 <- ggplot(ate.data, aes(xplust,yplusz_alt)) + 
  geom_point(aes(shape=z_alt, size=5, color=t), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15)) +
  geom_text(aes(label=z_lab), alpha=1/3, size=3)
plot7
```

```{r ate-plot9-output, ref.label="ate-plot9", fig.callout=TRUE, warning=FALSE}
```

---
# Assumption 2: Common Support
Someone of each type must be in both the treated and untreated groups

--
$$0 < \text{Pr}(W=1|X) <1$$

---
# Assumption 2: Common Support
```{r, ref.label="ate-plot5", fig.callout=TRUE, warning=FALSE}
```

---
# Violation of Common Support
```{r ate-overlap, echo=F, include=F}
ate.new <- ate.data %>% filter(z_alt=="blue" | 
                                 (z_alt=="red" & t==-1) | 
                                 (z_alt=="yellow" & t==1))

plot.overlap <- ggplot(ate.new, aes(xplust,yplusz_alt)) + 
  geom_point(aes(shape=z_alt, size=5, color=t), alpha=1/2) + 
  theme_classic() +
  theme(legend.position="none", axis.line=element_blank(),
        axis.text=element_blank(), axis.title=element_blank(),
        axis.ticks=element_blank()) +
  expand_limits(x=c(-.3,.8), y=c(-5,15))
plot.overlap
```

```{r, ref.label="ate-overlap", fig.callout=TRUE, warning=FALSE}
```

<!-- New Section -->
---
class: inverse, center, middle
name: methods

# Causal Inference with Observational Data

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# Fundamental Problem of Causal Inference

Potential outcomes:
- $Y_{i}(1)$ for $W_{i}=1$
- $Y_{i}(0)$ for $W_{i}=0$


--
<br>
<br>

Average treatment effect is $E[Y_{i}(1)-Y_{i}(0)]$, but: 
- $E[Y_{i}|W_{i}=1] \neq E[Y_{i}(1)]$
- $E[Y_{i}|W_{i}=0] \neq E[Y_{i}(0)]$

---
# Fundamental Problem of Causal Inference

- We don't observe the counterfactual outcome...what would have happened if a treated unit was actually untreated.

- *ALL* attempts at causal inference represent some attempt at estimating the counterfactual outcome. We need an estimate for $E[Y_{i}(0)]$ among those that were treated, and vice versa for $E[Y_{i}(1)]$.


---
# Causal inference with observational data
Solution for now: find covariates $X_{i}$ such that the following assumptions are plausible: <br>

1. Selection on observables: $$Y_{i}(1), Y_{i}(0) \perp\!\!\!\perp W_{i} | X_{i}$$
2. Common support: $$0 < \text{Pr}(W_{i}=1|X_{i}) < 1$$

--
<br>

Then we can use $X_{i}$ to group observations and use expectations for control as the predicted counterfactuals among treated, and vice versa. 

---
# Causal inference with observational data
With selection on observables and common support:
1. Matching estimators: $$E[Y_{i}(1) - Y_{i}(0)] = E[ E[Y_{i}|W_{i}=1, X_{i}] - E[Y_{i}|W_{i}=0, X_{i}] ]$$
2. Regression estimators: $$E[Y_{i}(1) - Y_{i}(0)] = E[ E[Y_{i}|W_{i}=1, X_{i}] ] - E[ E[Y_{i}|W_{i}=0, X_{i}] ]$$

--
<br>
What's the difference?

---
# Matching
```{r ate-plot8-output, ref.label="ate-plot8", fig.callout=TRUE, warning=FALSE}
```

---
# Regression
```{r regression, echo=F, include=F}
eq1.start <- mean.x1-.1
eq1.end <- mean.x1+.1
eq2.start <- mean.x0-.1
eq2.end <- mean.x0+.1

eq.y <- mean.blue-1.3
ans.y <- eq.y-1.1
mid=(mean.x0+mean.x1)/2
plot6 + annotate("text",x=mean.x0, y=mean.blue, label="E[Y(1)|c]", size=4) +
  annotate("text", x=mean.x1, y=mean.blue, label="E[Y(0)|c]", size=4) +
  annotate("text",x=mean.x0, y=mean.yellow, label="E[Y(1)|s]", size=4) +
  annotate("text",x=mean.x1, y=mean.yellow, label="E[Y(0)|s]", size=4) +
  annotate("text",x=mean.x0, y=mean.red, label="E[Y(1)|t]", size=4) +
  annotate("text",x=mean.x1, y=mean.red, label="E[Y(0)|t]", size=4) +
  annotate("segment", x = eq1.start , xend = eq1.end, y = eq.y, yend = eq.y, colour = "black") +
  annotate("segment", x = eq2.start , xend = eq2.end, y = eq.y, yend = eq.y, colour = "black") +  
  annotate("text",x=mean.x1, y=ans.y, label="E[Y(1)]", size=4) +
  annotate("text",x=mean.x0, y=ans.y, label="E[Y(0)]", size=4) +
  annotate("text",x=mid, y=ans.y, label="-", size=4) +    
  annotate("text",x=x.end, y=ans.y, label="=E[Y(1)-Y(0)]", size=4)  
```

```{r regression-output, ref.label="regression", fig.callout=TRUE, warning=FALSE}
```

---
# Estimation options
- Matching
- Weighting
- Regression
- Doubly-robust weighting + regression (won't cover)


---
# Matching: The process
1. For each observation $i$, find the $m$ "nearest" neighbors, $J_{m}(i)$. 
2. Impute $\hat{Y}_{i}(0)$ and $\hat{Y}_{i}(1)$ for each observation:<br>
$$\hat{Y}_{i}(0) = \begin{cases}
    Y_{i} & \text{if} & W_{i}=0 \\
    \frac{1}{m} \sum_{j \in J_{m}(i)} Y_{j} & \text{if} & W_{i}=1 
\end{cases}$$
$$\hat{Y}_{i}(1) = \begin{cases}
    Y_{i} & \text{if} & W_{i}=1 \\
    \frac{1}{m} \sum_{j \in J_{m}(i)} Y_{j} & \text{if} & W_{i}=0 
\end{cases}$$

3. Form "matched" ATE:<br>
$\hat{\delta}^{\text{match}} = \frac{1}{N} \sum_{i=1}^{N} \left(\hat{Y}_{i}(1) - \hat{Y}_{i}(0) \right)$

---
# Matching: Defining "nearest"

1. Euclidean distance:<br>
$\sum_{k=1}^{K} (X_{ik} - X_{jk})^{2}$

2. Scaled Euclidean distance:<br>
$\sum_{k=1}^{K} \frac{1}{\sigma_{X_{k}}^{2}} (X_{ik} - X_{jk})^{2}$

3. Mahalanobis distance:<br>
$(X_{i} - X_{j})' \Sigma_{X}^{-1} (X_{i} - X_{j})$

---
# Animation for matching
```{r animate, message=FALSE, warning=FALSE, include=FALSE}
df <- data.frame(xaxisTime=runif(60),Treated=c(rep("Treated",5),rep("Control",55))) %>%
  mutate(Y = 3+.4*xaxisTime+1*(Treated=="Treated")+rnorm(60),
         state="1")

#Make sure the treated obs aren't too close together, that makes it confusing
df[df$Treated=="Treated",]$xaxisTime <- c(1:5/6)+(runif(5)-.5)*.1

caliper <- .02

df <- df %>%
  mutate(bins = c(rep(filter(df,Treated=="Treated")$xaxisTime-caliper,6),
                  rep(filter(df,Treated=="Treated")$xaxisTime+caliper,6))) %>%
  #There has to be a less clunky way to do this
  rowwise() %>%
  mutate(matchmeas = min(abs(xaxisTime-filter(df,Treated=="Treated")$xaxisTime))) %>%
  mutate(match = matchmeas < caliper) %>%
  group_by(Treated,match) %>%
  mutate(mean_Y = ifelse(match==1,mean(Y),NA)) %>%
  ungroup()


#Check how many matches we have before proceeding; regenerate randomized data
#until we have a decent number
table(filter(df,Treated=="Control")$match)

dffull <- rbind(
  #Step 1: Raw data only
  df %>% mutate(bins=NA,mean_Y=NA,state='1. Start with raw data.'),
  #Step 2: Add Y-lines
  df %>% mutate(mean_Y=NA,state='2. Look for Controls with similar X values to the Treatments.'),
  #Step 3: Drop unmatch obs
  df %>% mutate(Y = ifelse(match==1,Y,NA),mean_Y=NA,state="3. Keep Controls only if they're similar enough."),
  #Step 4: Take means
  df %>% mutate(Y = ifelse(match==1,Y,NA),bins=NA,state="4. Among what's kept, see what the treatment explains."),
  #Step 5: Eliminate everything but the means
  df %>% mutate(Y = ifelse(match==1,mean_Y,NA),bins=NA,state="5. Ignore everything not explained by treatment."),
  #Step 6: Get treatment effect
  df %>% mutate(Y = NA,bins=NA,state="6. The treatment effect is the remaining difference."))


p <- ggplot(dffull,aes(y=Y,x=xaxisTime,color=Treated,size=Treated))+geom_point()+
  geom_vline(aes(xintercept=bins))+
  geom_hline(aes(yintercept=mean_Y,color=Treated))+
  geom_segment(aes(x=.5,xend=.5,
                   y=ifelse(state=="6. The treatment effect is the remaining difference.",
                            filter(df,Treated=="Treated")$mean_Y[1],NA),
                   yend=filter(df,Treated=="Control",match==TRUE)$mean_Y[1]),size=1.5,color='blue')+
  scale_color_colorblind()+
  scale_size_manual(values=c(2,3))+xlab("X")+
  guides(fill=guide_legend(title="Group"))+
  labs(title = 'The Effect of Treatment on Y while Matching on X (with a caliper) \n{next_state}')+
  transition_states(state,transition_length=c(12,16,16,16,16,16),state_length=c(50,36,30,30,30,50),wrap=FALSE)+
  ease_aes('sine-in-out')+
  exit_fade()+enter_fade()

anim.p <- animate(p,nframes=200)
anim_save("match_animate.gif",
          anim.p,path="D:/CloudStation/Professional/Teaching Material/Emory/Econ 470 - Economics and Health Policy/03-Selection-HospitalPricing/pics")
```

.center[
  ![:scale 900px](pics/match_animate.gif)
]


---
# Weighting

1. Estimate propensity score `ps <- glm(W~X, family=binomial, data)`, denoted $\hat{\pi}(X_{i})$
2. Weight by inverse of propensity score<br>
.center[
$\hat{\mu}_{1} = \frac{ \sum_{i=1}^{N} \frac{Y_{i} W_{i}}{\hat{\pi}(X_{i})} }{ \sum_{i=1}^{N} \frac{W_{i}}{\hat{\pi}(X_{i})} }$ and 
$\hat{\mu}_{0} = \frac{ \sum_{i=1}^{N} \frac{Y_{i} (1-W_{i})}{1-\hat{\pi}(X_{i})} }{ \sum_{i=1}^{N} \frac{1-W_{i}}{1-\hat{\pi}(X_{i})} }$
]
3. Form "inverse-propensity weighted" ATE:<br>
.center[
$\hat{\delta}^{IPW} = \hat{\mu}_{1} - \hat{\mu}_{0}$
]

---
# Regression
1. Regress $Y_{i}$ on $X_{i}$ among $W_{i}=1$ to form $\hat{\mu}_{1}(X_{i})$
2. Regress $Y_{i}$ on $X_{i}$ among $W_{i}=0$ to form $\hat{\mu}_{0}(X_{i})$
3. Form difference in predictions:<br>
.center[
$$\hat{\delta}^{reg} = \frac{1}{N} \sum_{i=1}^{N} \left(\hat{\mu}_{1}(X_{i}) - \hat{\mu}_{0}(X_{i})\right)$$
]

---
# Regression

Or estimate in one step, 
.center[
$$Y_{i} = \delta W_{i} + \beta X_{i} + W_{i} \times \left(X_{i} - \bar{X}\right) \gamma + \varepsilon_{i}$$
]


---
# Animation for regression
```{r reg-animate, message=FALSE, warning=FALSE, include=FALSE}
df <- data.frame(W = as.integer((1:200>100))) %>%
  mutate(X = .5+2*W + rnorm(200)) %>%
  mutate(Y = -.5*X + 4*W + 1 + rnorm(200),time="1") %>%
  group_by(W) %>%
  mutate(mean_X=mean(X),mean_Y=mean(Y)) %>%
  ungroup()

#Calculate correlations
before_cor <- paste("1. Start with raw data. Correlation between X and Y: ",round(cor(df$X,df$Y),3),sep='')
after_cor <- paste("6. Analyze what's left! Correlation between X and Y controlling for W: ",round(cor(df$X-df$mean_X,df$Y-df$mean_Y),3),sep='')




#Add step 2 in which X is demeaned, and 3 in which both X and Y are, and 4 which just changes label
dffull <- rbind(
  #Step 1: Raw data only
  df %>% mutate(mean_X=NA,mean_Y=NA,time=before_cor),
  #Step 2: Add x-lines
  df %>% mutate(mean_Y=NA,time='2. Figure out what differences in X are explained by W'),
  #Step 3: X de-meaned 
  df %>% mutate(X = X - mean_X,mean_X=0,mean_Y=NA,time="3. Remove differences in X explained by W"),
  #Step 4: Remove X lines, add Y
  df %>% mutate(X = X - mean_X,mean_X=NA,time="4. Figure out what differences in Y are explained by W"),
  #Step 5: Y de-meaned
  df %>% mutate(X = X - mean_X,Y = Y - mean_Y,mean_X=NA,mean_Y=0,time="5. Remove differences in Y explained by W"),
  #Step 6: Raw demeaned data only
  df %>% mutate(X = X - mean_X,Y = Y - mean_Y,mean_X=NA,mean_Y=NA,time=after_cor))

p <- ggplot(dffull,aes(y=Y,x=X,color=as.factor(W)))+geom_point()+
  geom_vline(aes(xintercept=mean_X,color=as.factor(W)))+
  geom_hline(aes(yintercept=mean_Y,color=as.factor(W)))+
  guides(color=guide_legend(title="W"))+
  scale_color_colorblind()+
  labs(title = 'The Relationship between Y and X, Controlling for a Binary Variable W \n{next_state}')+
  transition_states(time,transition_length=c(12,32,12,32,12,12),state_length=c(160,100,75,100,75,160),wrap=FALSE)+
  ease_aes('sine-in-out')+
  exit_fade()+enter_fade()

anim.reg <- animate(p,nframes=200)
anim_save("reg_animate.gif",
          anim.reg,path="D:/CloudStation/Professional/Teaching Material/Emory/Econ 470 - Economics and Health Policy/03-Selection-HospitalPricing/pics")
```

.center[
  ![:scale 900px](pics/reg_animate.gif)
]

---
# Simulated data
Now let's do some matching, re-weighting, and regression with simulated data:
```{r}
n <- 5000
select.dat <- tibble(
  x = runif(n, 0, 1),
  z = rnorm(n, 0, 1),
  w = (x>0.65),
  y = -2.5 + 4*w + 1.5*x + rnorm(n,0,1),
  w_alt = ( x + z > 0.35),
  y_alt = -2.5 + 4*w_alt + 1.5*x + 2.25*z + rnorm(n,0,1)
)
```

---
# Simulation: nearest neighbor matching
```{r}
nn.est1 <- Matching::Match(Y=select.dat$y,
                            Tr=select.dat$w,
                            X=select.dat$x,
                            M=1,
                            Weight=1,
                            estimand="ATE")
summary(nn.est1)
```

---
# Simulation: nearest neighbor matching 
```{r}
nn.est2 <- Matching::Match(Y=select.dat$y,
                            Tr=select.dat$w,
                            X=select.dat$x,
                            M=1,
                            Weight=2, #<<
                            estimand="ATE")
summary(nn.est2)
```


---
# Simulation: regression
```{r}
reg1.dat <- select.dat %>% filter(w==1)
reg1 <- lm(y ~ x, data=reg1.dat)

reg0.dat <- select.dat %>% filter(w==0)
reg0 <- lm(y ~ x, data=reg0.dat)
pred1 <- predict(reg1,new=select.dat)
pred0 <- predict(reg0,new=select.dat)
mean(pred1-pred0)
```


---
# Violation of selection on observables
.pull-left[
<u>NN Matching</u>
```{r}
nn.est3 <- Matching::Match(Y=select.dat$y_alt,
                            Tr=select.dat$w_alt,
                            X=select.dat$x,
                            M=1,
                            Weight=2,
                            estimand="ATE")
summary(nn.est3)
```
]

.pull-right[
<u>Regression</u>
```{r}
reg1.dat <- select.dat %>% filter(w_alt==1)
reg1 <- lm(y_alt ~ x, data=reg1.dat)

reg0.dat <- select.dat %>% filter(w_alt==0)
reg0 <- lm(y_alt ~ x, data=reg0.dat)
pred1_alt <- predict(reg1,new=select.dat)
pred0_alt <- predict(reg0,new=select.dat)
mean(pred1_alt-pred0_alt)
```
]


<!-- New Section -->
---
class: inverse, center, middle
name: hcris

# Understanding HCRIS Data

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# What is HCRIS?
Healthcare Cost Report Information System ('cost reports')
- Nursing Homes (SNFs)
- Hospice
- Home Health Agencies
- Hospitals 

---
# Hospital Cost Reports

.center[
  ![:scale 800px](pics/HCRIS.png)
]

---
# The Data

Let's work with the [HCRIS GitHub repository](https://github.com/imccart/HCRIS). But forming the dataset is up to you this time.

--
.center[
  ![:scale 700px](https://media.giphy.com/media/26DNdV3b6dqn1jzR6/giphy.gif)
]


---
# The Data
```{r eval=T, include=F}
hcris.data <- read_rds("D:/CloudStation/Professional/Research Projects/_Git/HCRIS/data/HCRIS_Data.rds")
```

```{r hospital-count, eval=FALSE, warning=FALSE}
hcris.data %>% 
  ggplot(aes(x=as.factor(year))) + 
  geom_bar() +
  labs(
    x="Year",
    y="Number of Hospitals",
    title="Number of Hospitals per Year"
  ) + theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust=1))
```
.plot-callout[
```{r hospital-count-callout, ref.label="hospital-count", fig.callout=TRUE, warning=FALSE}
```
]


---
# Number of hospitals

```{r hospital-count-output, ref.label="hospital-count", fig.callout=TRUE, warning=FALSE}
```

---
# Estimating hospital prices
```{r price-calc}
hcris.data <- hcris.data %>%
  mutate( discount_factor = 1-tot_discounts/tot_charges,
          price_num = (ip_charges + icu_charges + ancillary_charges)*discount_factor - tot_mcare_payment,
          price_denom = tot_discharges - mcare_discharges,
          price = price_num/price_denom)
```

---
# Estimating hospital prices

.left-code[
```{r price-plot1, fig.show="hide"}
hcris.data %>% group_by(year) %>% 
  filter(price_denom>10, !is.na(price_denom), 
         price_num>0, !is.na(price_num)) %>%  
  select(price, year) %>% 
  summarize(mean_price=mean(price, na.rm=TRUE)) %>%
  ggplot(aes(x=as.factor(year), y=mean_price)) + 
  geom_line(aes(group=1)) +
  labs(
    x="Year",
    y="Average Hospital Price",
    title="Hospital Prices per Year"
  ) + scale_y_continuous(labels=comma) +
  theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust=1))
```
]

.right-plot[
![](`r knitr::fig_chunk("price-plot1","png")`)
]


---
# Estimating hospital prices

.left-code[
```{r price-plot2, fig.show="hide"}
hcris.data %>% group_by(year) %>% 
  filter(price_denom>100, !is.na(price_denom), 
         price_num>0, !is.na(price_num),
         price<100000) %>%   #<<
  select(price, year) %>% 
  summarize(mean_price=mean(price, na.rm=TRUE)) %>%
  ggplot(aes(x=as.factor(year), y=mean_price)) + 
  geom_line(aes(group=1)) +
  labs(
    x="Year",
    y="Average Hospital Price",
    title="Hospital Prices per Year"
  ) + scale_y_continuous(labels=comma) +
  theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust=1))
```
]

.right-plot[
![](`r knitr::fig_chunk("price-plot2","png")`)
]


<!-- New Section -->
---
class: inverse, center, middle
name: price_pfp

# Pricing and Pay for Performance

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# Penalized hospitals
```{r final-data}
final.hcris <- hcris.data %>% ungroup() %>%
  filter(price_denom>100, !is.na(price_denom), 
         price_num>0, !is.na(price_num),
         price<100000, 
         beds>30, year==2012) %>%  #<<
  mutate( hvbp_payment = ifelse(is.na(hvbp_payment),0,hvbp_payment),
          hrrp_payment = ifelse(is.na(hrrp_payment),0,abs(hrrp_payment)), #<<
    penalty = (hvbp_payment-hrrp_payment<0)) #<<
```

```{r, include=F}
mean.pen <- round(mean(final.hcris$price[which(final.hcris$penalty==1)]),2)
mean.nopen <- round(mean(final.hcris$price[which(final.hcris$penalty==0)]),2)
```

---
# Summary stats
Always important to look at your data before doing any formal analysis. Ask yourself a few questions:
1. Are the magnitudes reasonable?

2. Are there lots of missing values?

3. Are there clear examples of misreporting?

---
# Summary stats

.pull-left[
```{r}
summary(hcris.data$price)
plot(density(hcris.data$price, na.rm=TRUE))
```
]

.pull-right[
```{r}
summary(final.hcris$price)
plot(density(final.hcris$price))
```
]

---
# Dealing with problems
We've adopted a very brute force way to deal with outlier prices. Other approaches include:
1. Investigate very closely the hospitals with extreme values

2. Winsorize at certain thresholds (replace extreme values with pre-determined thresholds)

3. Impute prices for extreme hospitals

---
# Differences among penalized hospitals
- Mean price among penalized hospitals: `r format(mean.pen, big.mark=",")`
- Mean price among non-penalized hospitals: `r format(mean.nopen, big.mark=",")`
- Mean difference: `r format(mean.pen-mean.nopen, big.mark=",")`

---
# Comparison of hospitals
Are penalized hospitals sufficiently similar to non-penalized hospitals?

--
<br>
<br>
Let's look at covariate balance using a love plot, part of the `library(cobalt)` package.

---
# Love plots without adjustment

```{r include=FALSE}
lp.vars <- final.hcris %>% 
  select(beds, mcaid_discharges, penalty, ip_charges, 
         mcare_discharges, tot_mcare_payment, price) %>%
  filter(complete.cases(.))
lp.covs <- lp.vars %>% select(-c("penalty","price"))
```

```{r cov-balance, eval=FALSE, warning=FALSE}
love.plot(bal.tab(lp.covs,treat=lp.vars$penalty), colors="black", shapes="circle", threshold=0.1) + 
  theme_bw() + theme(legend.position="none")
```

.plot-callout[
```{r cov-balance-callout, ref.label="cov-balance", fig.callout=TRUE, warning=FALSE}
```
]


---
# Love plots without adjustment

```{r cov-balance-output, ref.label="cov-balance", fig.callout=TRUE, warning=FALSE}
```

---
# Using matching to improve balance
Some things to think about:
- exact versus nearest neighbor
- with or without ties (and how to break ties)
- measure of distance

---
# 1. Exact Matching
```{r exact-matching1, echo=TRUE}
m.exact <- Matching::Match(Y=lp.vars$price,
                           Tr=lp.vars$penalty,
                           X=lp.covs,
                           M=1,
                           exact=TRUE) #<<
print(m.exact)
```

---
# 1. Exact Matching (on a subset)
```{r exact-matching2, echo=TRUE}
lp.covs2 <- lp.covs %>% select(beds, mcaid_discharges)
m.exact <- Matching::Match(Y=lp.vars$price,
                           Tr=lp.vars$penalty,
                           X=lp.covs2,
                           M=1,
                           exact=TRUE,
                           estimand="ATE") #<<
```

---
# 1. Exact Matching (on a subset)
```{r lp-exact, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.exact, covs = lp.covs2, treat = lp.vars$penalty),  
          threshold=0.1, 
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-exact-callout, ref.label="lp-exact", fig.callout=TRUE, warning=FALSE}
```
]


---
# 1. Exact Matching (on a subset)

```{r lp-exact-output, ref.label="lp-exact", fig.callout=TRUE, warning=FALSE}
```


---
# 2. Nearest neighbor matching (inverse variance)
```{r var-match1, echo=TRUE, warning=FALSE}
m.nn.var <- Matching::Match(Y=lp.vars$price,
                            Tr=lp.vars$penalty,
                            X=lp.covs,
                            M=4,  #<<
                            Weight=1,
                            estimand="ATE")

v.name=data.frame(new=c("Beds","Medicaid Discharges", "Inaptient Charges",
                   "Medicare Discharges", "Medicare Payments"))
```

---
# 2. Nearest neighbor matching (inverse variance)

```{r lp-var-dist1, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.nn.var, covs = lp.covs, treat = lp.vars$penalty), 
          threshold=0.1, 
          var.names=v.name,
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-var-callout1, ref.label="lp-var-dist1", fig.callout=TRUE, warning=FALSE}
```
]


---
# 2. Nearest neighbor matching (inverse variance)

```{r lp-var-output1, ref.label="lp-var-dist1", fig.callout=TRUE, warning=FALSE}
```

---
# 2. Nearest neighbor matching (inverse variance)
```{r var-match2, echo=TRUE, warning=FALSE}
m.nn.var2 <- Matching::Match(Y=lp.vars$price,
                             Tr=lp.vars$penalty,
                             X=lp.covs,
                             M=1,   #<<
                             Weight=1,
                             estimand="ATE")
```

---
# 2. Nearest neighbor matching (inverse variance)

```{r lp-var-dist2, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.nn.var2, covs = lp.covs, treat = lp.vars$penalty), 
          threshold=0.1, 
          var.names=v.name,
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-var-callout2, ref.label="lp-var-dist2", fig.callout=TRUE, warning=FALSE}
```
]


---
# 2. Nearest neighbor matching (inverse variance)

```{r lp-var-output2, ref.label="lp-var-dist2", fig.callout=TRUE, warning=FALSE}
```


---
# 2. Nearest neighbor matching (Mahalanobis)
```{r md-match1, echo=TRUE, warning=FALSE}
m.nn.md <- Matching::Match(Y=lp.vars$price,
                           Tr=lp.vars$penalty,
                           X=lp.covs,
                           M=1,
                           Weight=2,
                           estimand="ATE")                           
```

---
# 2. Nearest neighbor matching (Mahalanobis)

```{r lp-md-dist1, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.nn.md, covs = lp.covs, treat = lp.vars$penalty), 
          threshold=0.1, 
          var.names=v.name,
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-md-callout1, ref.label="lp-md-dist1", fig.callout=TRUE, warning=FALSE}
```
]


---
# 2. Nearest neighbor matching (Mahalanobis)

```{r lp-md-output1, ref.label="lp-md-dist1", fig.callout=TRUE, warning=FALSE}
```

---
# 2. Nearest neighbor matching (propensity score)
```{r ps-match, echo=TRUE, warning=FALSE}
logit.model <- glm(penalty ~ beds + mcaid_discharges + ip_charges + mcare_discharges +
            tot_mcare_payment, family=binomial, data=lp.vars)
ps <- fitted(logit.model)
m.nn.ps <- Matching::Match(Y=lp.vars$price,
                           Tr=lp.vars$penalty,
                           X=ps,
                           M=1,
                           estimand="ATE")
```

---
# 2. Nearest neighbor matching (propensity score)

```{r lp-ps-match, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.nn.ps, covs = lp.covs, treat = lp.vars$penalty), 
          threshold=0.1, 
          var.names=v.name,
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-ps-callout, ref.label="lp-ps-match", fig.callout=TRUE, warning=FALSE}
```
]


---
# 2. Nearest neighbor matching (propensity score)

```{r lp-ps-output, ref.label="lp-ps-match", fig.callout=TRUE, warning=FALSE}
```

---
# 3. Weighting
```{r echo=F}
ggplot(lp.vars, aes(x=ps)) + geom_histogram() + 
  facet_wrap(~ penalty, ncol=1) +
  theme_bw()
```

---
# Results: Exact matching
```{r echo=FALSE}
summary(m.exact)
```


---
# Results: Nearest neighbor

- Inverse variance
```{r echo=FALSE}
summary(m.nn.var2)
```

---
# Results: Nearest neighbor

- Mahalanobis
```{r echo=FALSE}
summary(m.nn.md)
```

---
# Results: Nearest neighbor

- Propensity score
```{r echo=FALSE}
summary(m.nn.ps)
```


---
# Results: IPW weighting

```{r}
lp.vars <- lp.vars %>%
  mutate(ipw = case_when(
    penalty==1 ~ 1/ps,
    penalty==0 ~ 1/(1-ps),
    TRUE ~ NA_real_
  ))
mean.t1 <- lp.vars %>% filter(penalty==1) %>%
  select(price, ipw) %>% summarize(mean_p=weighted.mean(price,w=ipw))
mean.t0 <- lp.vars %>% filter(penalty==0) %>%
  select(price, ipw) %>% summarize(mean_p=weighted.mean(price,w=ipw))
mean.t1$mean_p - mean.t0$mean_p
```

---
# Results: IPW weighting with regression

```{r}
ipw.reg <- lm(price ~ penalty, data=lp.vars, weights=ipw)
summary(ipw.reg)
```

---
# Results: Regression

```{r}
reg1.dat <- lp.vars %>% filter(penalty==1, complete.cases(.))
reg1 <- lm(price ~ beds+ mcaid_discharges + ip_charges + mcare_discharges +
            tot_mcare_payment, data=reg1.dat)

reg0.dat <- lp.vars %>% filter(penalty==0, complete.cases(.))
reg0 <- lm(price ~ beds + mcaid_discharges + ip_charges + mcare_discharges +
            tot_mcare_payment, data=reg0.dat)
pred1 <- predict(reg1,new=lp.vars)
pred0 <- predict(reg0,new=lp.vars)
mean(pred1-pred0)
```

---
# Results: Regression in one step

```{r}
reg.dat <- lp.vars %>% ungroup() %>% filter(complete.cases(.)) %>%
  mutate(beds_diff = penalty*(beds - mean(beds)),
         mcaid_diff = penalty*(mcaid_discharges - mean(mcaid_discharges)),
         ip_diff = penalty*(ip_charges - mean(ip_charges)),
         mcare_diff = penalty*(mcare_discharges - mean(mcare_discharges)),
         mpay_diff = penalty*(tot_mcare_payment - mean(tot_mcare_payment)))
reg <- lm(price ~ penalty + beds + mcaid_discharges + ip_charges + mcare_discharges + tot_mcare_payment + 
            beds_diff + mcaid_diff + ip_diff + mcare_diff + mpay_diff,
          data=reg.dat)
```

---
# Results: Regression in one step

```{r echo=FALSE}
summary(reg)
```


---
# Summary of ATEs
1. Exact matching: `r round(m.exact$est[1],2)`
2. NN matching, inverse variance: `r round(m.nn.var2$est[1],2)`
3. NN matching, mahalanobis: `r round(m.nn.md$est[1],2)`
4. NN matching, pscore: `r round(m.nn.ps$est[1],2)`
5. Inverse pscore weighting: `r round(mean.t1$mean_p - mean.t0$mean_p,2)`
6. IPW regression: `r round(ipw.reg$coeff[2],2)`
7. Regression: `r round(mean(pred1-pred0),2)`
8. Regression 1-step: `r round(reg$coeff[2],2)`


<!-- New Section -->
---
class: inverse, center, middle
name: summary

# So what have we learned?

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>

---
# Key assumptions for causal inference
1. Selection on observables
2. Common support

--
<br>
<br>

These become more nuanced but the intuition is the same in almost all questions of causal inference.

---
# Causal effect assuming selection on observables
If we assume selection on observables holds, then we only need to condition on the relevant covariates to identify a causal effect. But we still need to ensure common support...<br>

--
<br>
1. Matching
2. Reweighting
3. Regression

